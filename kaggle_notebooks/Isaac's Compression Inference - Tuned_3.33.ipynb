{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986bf073",
   "metadata": {
    "papermill": {
     "duration": 0.003194,
     "end_time": "2025-04-24T19:18:46.926246",
     "exception": false,
     "start_time": "2025-04-24T19:18:46.923052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ARC-AGI Without Pretraining - Official Competition Template Version\n",
    "This file interfaces between the kaggle competition website and the rest of the solution code, which is included in the input files.\n",
    "\n",
    "The main differences between this notebook and the method in the ARC-AGI Without Pretraining blog post aim to parallelize the solving of many puzzles at once using all the CPUs and GPUs that are offered in this competition. In the blog post, we solved puzzles in series, vastly underutilized one RTX 4070 GPU, and blew past the time budget. Instead, what we do in this notebook is:\n",
    "- We run 2 steps of every puzzle to determine how much memory each puzzle uses.\n",
    "- We run 10 steps of every puzzle at optimal puzzle parallelization under memory constraint to determine how much time per step we need to solve the puzzles in bulk.\n",
    "- We run as many steps as we can at optimal puzzle parallelization under memory constraint to fit a 12 hour budget.\n",
    "- We have changed layers.direction_share() to make it run faster, and got something like a 5-10% speedup.\n",
    "\n",
    "If the dataset size is 120 puzzles, we should expect this to get ~2300 steps in per puzzle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79aa875",
   "metadata": {
    "papermill": {
     "duration": 0.002347,
     "end_time": "2025-04-24T19:18:46.931494",
     "exception": false,
     "start_time": "2025-04-24T19:18:46.929147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a962f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:18:46.937307Z",
     "iopub.status.busy": "2025-04-24T19:18:46.937050Z",
     "iopub.status.idle": "2025-04-24T19:18:51.010620Z",
     "shell.execute_reply": "2025-04-24T19:18:51.009921Z"
    },
    "papermill": {
     "duration": 4.078109,
     "end_time": "2025-04-24T19:18:51.012080",
     "exception": false,
     "start_time": "2025-04-24T19:18:46.933971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import importlib\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append('/kaggle/input/compressarc')\n",
    "\n",
    "# This little block of code does \"import preprocessing\" but avoids a name collision with another module\n",
    "module_path = \"/kaggle/input/compressarc/preprocessing.py\"\n",
    "module_name = \"preprocessing\"\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "preprocessing = importlib.util.module_from_spec(spec)\n",
    "sys.modules[module_name] = preprocessing\n",
    "spec.loader.exec_module(preprocessing)\n",
    "import train\n",
    "import arc_compressor\n",
    "import initializers\n",
    "import multitensor_systems\n",
    "import layers\n",
    "import solution_selection\n",
    "import visualization\n",
    "import solve_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911cb008",
   "metadata": {
    "papermill": {
     "duration": 0.002466,
     "end_time": "2025-04-24T19:18:51.017578",
     "exception": false,
     "start_time": "2025-04-24T19:18:51.015112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting all the task names, setting defaults and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37308ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:18:51.023493Z",
     "iopub.status.busy": "2025-04-24T19:18:51.023142Z",
     "iopub.status.idle": "2025-04-24T19:18:51.189062Z",
     "shell.execute_reply": "2025-04-24T19:18:51.188391Z"
    },
    "papermill": {
     "duration": 0.170446,
     "end_time": "2025-04-24T19:18:51.190557",
     "exception": false,
     "start_time": "2025-04-24T19:18:51.020111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_default_device('cuda')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    start_time = time.time()\n",
    "    end_time = start_time + 12*3600 - 300\n",
    "\n",
    "    n_cpus = multiprocessing.cpu_count()\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "\n",
    "    # Find all the puzzle names\n",
    "    split = \"test\"\n",
    "    with open(f'../input/arc-prize-2025/arc-agi_{split}_challenges.json', 'r') as f:\n",
    "        problems = json.load(f)\n",
    "    task_names = list(problems.keys())\n",
    "    del problems\n",
    "    n_tasks = len(task_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d7952",
   "metadata": {
    "papermill": {
     "duration": 0.00246,
     "end_time": "2025-04-24T19:18:51.196034",
     "exception": false,
     "start_time": "2025-04-24T19:18:51.193574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Function that can spawn processes and schedule them on GPUs to take up each GPUs quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547fb105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:18:51.202113Z",
     "iopub.status.busy": "2025-04-24T19:18:51.201865Z",
     "iopub.status.idle": "2025-04-24T19:18:51.209989Z",
     "shell.execute_reply": "2025-04-24T19:18:51.209406Z"
    },
    "papermill": {
     "duration": 0.012221,
     "end_time": "2025-04-24T19:18:51.210962",
     "exception": false,
     "start_time": "2025-04-24T19:18:51.198741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parallelize_runs(gpu_quotas, task_usages, n_iterations, verbose=False):\n",
    "    gpu_quotas = gpu_quotas[:]\n",
    "    # Schedule the tasks greedily to max out memory usage\n",
    "    t = time.time()\n",
    "    tasks_started = [False for i in range(n_tasks)]\n",
    "    tasks_finished = [False for i in range(n_tasks)]\n",
    "    processes = [None for i in range(n_tasks)]\n",
    "    process_gpu_ids = [None for i in range(n_tasks)]\n",
    "    with multiprocessing.Manager() as manager:\n",
    "        memory_dict = manager.dict()\n",
    "        solutions_dict = manager.dict()\n",
    "        error_queue = manager.Queue()\n",
    "        while not all(tasks_finished):\n",
    "            if not error_queue.empty():\n",
    "                raise ValueError(error_queue.get())\n",
    "            for i in range(n_tasks):\n",
    "                if tasks_started[i] and not tasks_finished[i]:\n",
    "                    processes[i].join(timeout=0)\n",
    "                    if not processes[i].is_alive():\n",
    "                        tasks_finished[i] = True\n",
    "                        gpu_quotas[process_gpu_ids[i]] += task_usages[i]\n",
    "                        if verbose:\n",
    "                            print(task_names[i], 'finished on gpu', process_gpu_ids[i],\n",
    "                                  'New quota is', gpu_quotas[process_gpu_ids[i]])\n",
    "            for gpu_id in range(n_gpus):\n",
    "                for i in range(n_tasks):\n",
    "                    enough_quota = gpu_quotas[gpu_id] > task_usages[i]\n",
    "                    enough_cpus = sum(map(int, tasks_started)) - sum(map(int, tasks_finished)) < n_cpus\n",
    "                    if not tasks_started[i] and enough_quota and enough_cpus:\n",
    "                        gpu_quotas[gpu_id] -= task_usages[i]\n",
    "                        args = (task_names[i], split, end_time, n_iterations, gpu_id, memory_dict, solutions_dict, error_queue)\n",
    "                        p = multiprocessing.Process(target=solve_task.solve_task, args=args)\n",
    "                        p.start()\n",
    "                        processes[i] = p\n",
    "                        tasks_started[i] = True\n",
    "                        process_gpu_ids[i] = gpu_id\n",
    "                        if verbose:\n",
    "                            print(task_names[i], 'started on gpu', process_gpu_ids[i],\n",
    "                                  'New quota is', gpu_quotas[process_gpu_ids[i]])\n",
    "            time.sleep(1)\n",
    "        if not error_queue.empty():\n",
    "            raise ValueError(error_queue.get())\n",
    "        memory_dict = dict(memory_dict)\n",
    "        solutions_dict = dict(solutions_dict)\n",
    "    time_taken = time.time() - t\n",
    "    if verbose:\n",
    "        print('All jobs finished in', time_taken, 'seconds.')\n",
    "    return memory_dict, solutions_dict, time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fca015",
   "metadata": {
    "papermill": {
     "duration": 0.002375,
     "end_time": "2025-04-24T19:18:51.216111",
     "exception": false,
     "start_time": "2025-04-24T19:18:51.213736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Measuring the amount of memory used for every task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbcdf46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:18:51.221742Z",
     "iopub.status.busy": "2025-04-24T19:18:51.221533Z",
     "iopub.status.idle": "2025-04-24T19:21:49.214596Z",
     "shell.execute_reply": "2025-04-24T19:21:49.213874Z"
    },
    "papermill": {
     "duration": 177.997624,
     "end_time": "2025-04-24T19:21:49.216247",
     "exception": false,
     "start_time": "2025-04-24T19:18:51.218623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gpu_memory_quotas = [torch.cuda.mem_get_info(i)[0] for i in range(n_gpus)]\n",
    "\n",
    "    gpu_task_quotas = [int(gpu_memory_quota // (4 * 1024**3)) for gpu_memory_quota in gpu_memory_quotas]\n",
    "    task_usages = [1 for i in range(n_tasks)]\n",
    "    memory_dict, _, _ = parallelize_runs(gpu_task_quotas, task_usages, 2, verbose=False)\n",
    "    \n",
    "    # Sort the tasks by decreasing memory usage\n",
    "    tasks = sorted(memory_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    task_names, task_memory_usages = zip(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedd3fe",
   "metadata": {
    "papermill": {
     "duration": 0.002458,
     "end_time": "2025-04-24T19:21:49.221914",
     "exception": false,
     "start_time": "2025-04-24T19:21:49.219456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Computing the time taken, while saturating memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dbbc1a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:21:49.227891Z",
     "iopub.status.busy": "2025-04-24T19:21:49.227664Z",
     "iopub.status.idle": "2025-04-24T19:25:45.428127Z",
     "shell.execute_reply": "2025-04-24T19:25:45.426512Z"
    },
    "papermill": {
     "duration": 236.211258,
     "end_time": "2025-04-24T19:25:45.435804",
     "exception": true,
     "start_time": "2025-04-24T19:21:49.224546",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  File \"/kaggle/input/compressarc/solve_task.py\", line 49, in solve_task\n    train.take_step(task, model, optimizer, train_step, train_history_logger)\n  File \"/kaggle/input/compressarc/train.py\", line 50, in take_step\n    logits, x_mask, y_mask, KL_amounts, KL_names, = model.forward()\n  File \"/kaggle/input/compressarc/arc_compressor.py\", line 120, in forward\n    x = layers.share_up(x, self.share_up_weights[layer_num])\n  File \"/kaggle/input/compressarc/layers.py\", line 250, in share_up\n    return share_direction(residual, share_up_weights, 1)\n  File \"/kaggle/input/compressarc/layers.py\", line 235, in share_direction\n    x = multitensor_systems.multify(share)(x)  # perform the cross-tensor communication\n  File \"/kaggle/input/compressarc/multitensor_systems.py\", line 207, in wrapper\n    iterate_and_assign(multitensor_system, result_data)\n  File \"/kaggle/input/compressarc/multitensor_systems.py\", line 200, in iterate_and_assign\n    output = fn(dims, *new_args, **new_kwargs)\n  File \"/kaggle/input/compressarc/layers.py\", line 199, in share\n    return sum(lower_xs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py\", line 106, in __torch_function__\n    return func(*args, **kwargs)\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 22.28 GiB of which 13.81 MiB is free. Process 9716 has 184.00 MiB memory in use. Process 14796 has 1.81 GiB memory in use. Process 14792 has 2.28 GiB memory in use. Process 15777 has 928.00 MiB memory in use. Process 15787 has 916.00 MiB memory in use. Process 15906 has 908.00 MiB memory in use. Process 15943 has 856.00 MiB memory in use. Process 15942 has 862.00 MiB memory in use. Process 15941 has 876.00 MiB memory in use. Process 16053 has 826.00 MiB memory in use. Process 16078 has 730.00 MiB memory in use. Process 16085 has 716.00 MiB memory in use. Process 16169 has 716.00 MiB memory in use. Process 16194 has 716.00 MiB memory in use. Process 16309 has 714.00 MiB memory in use. Process 16701 has 714.00 MiB memory in use. Process 16868 has 704.00 MiB memory in use. Process 16870 has 670.00 MiB memory in use. Process 16924 has 690.00 MiB memory in use. Process 16928 has 694.00 MiB memory in use. Process 16932 has 678.00 MiB memory in use. Process 16933 has 306.00 MiB memory in use. Process 16949 has 692.00 MiB memory in use. Process 17008 has 530.00 MiB memory in use. Process 17019 has 656.00 MiB memory in use. Process 17020 has 656.00 MiB memory in use. Process 17056 has 282.00 MiB memory in use. Process 17055 has 454.00 MiB memory in use. Process 17145 has 222.00 MiB memory in use. Process 17143 has 224.00 MiB memory in use. Process 17159 has 222.00 MiB memory in use. Process 17170 has 184.00 MiB memory in use. Of the allocated memory 223.90 MiB is allocated by PyTorch, and 6.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2f4e46558080>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msafe_gpu_memory_quotas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmemory_quota\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmemory_quota\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpu_memory_quotas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelize_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_gpu_memory_quotas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_memory_usages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-4ef21d5781ed>\u001b[0m in \u001b[0;36mparallelize_runs\u001b[0;34m(gpu_quotas, task_usages, n_iterations, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0merror_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtasks_started\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtasks_finished\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  File \"/kaggle/input/compressarc/solve_task.py\", line 49, in solve_task\n    train.take_step(task, model, optimizer, train_step, train_history_logger)\n  File \"/kaggle/input/compressarc/train.py\", line 50, in take_step\n    logits, x_mask, y_mask, KL_amounts, KL_names, = model.forward()\n  File \"/kaggle/input/compressarc/arc_compressor.py\", line 120, in forward\n    x = layers.share_up(x, self.share_up_weights[layer_num])\n  File \"/kaggle/input/compressarc/layers.py\", line 250, in share_up\n    return share_direction(residual, share_up_weights, 1)\n  File \"/kaggle/input/compressarc/layers.py\", line 235, in share_direction\n    x = multitensor_systems.multify(share)(x)  # perform the cross-tensor communication\n  File \"/kaggle/input/compressarc/multitensor_systems.py\", line 207, in wrapper\n    iterate_and_assign(multitensor_system, result_data)\n  File \"/kaggle/input/compressarc/multitensor_systems.py\", line 200, in iterate_and_assign\n    output = fn(dims, *new_args, **new_kwargs)\n  File \"/kaggle/input/compressarc/layers.py\", line 199, in share\n    return sum(lower_xs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py\", line 106, in __torch_function__\n    return func(*args, **kwargs)\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 22.28 GiB of which 13.81 MiB is free. Process 9716 has 184.00 MiB memory in use. Process 14796 has 1.81 GiB memory in use. Process 14792 has 2.28 GiB memory in use. Process 15777 has 928.00 MiB memory in use. Process 15787 has 916.00 MiB memory in use. Process 15906 has 908.00 MiB memory in use. Process 15943 has 856.00 MiB memory in use. Process 15942 has 862.00 MiB memory in use. Process 15941 has 876.00 MiB memory in use. Process 16053 has 826.00 MiB memory in use. Process 16078 has 730.00 MiB memory in use. Process 16085 has 716.00 MiB memory in use. Process 16169 has 716.00 MiB memory in use. Process 16194 has 716.00 MiB memory in use. Process 16309 has 714.00 MiB memory in use. Process 16701 has 714.00 MiB memory in use. Process 16868 has 704.00 MiB memory in use. Process 16870 has 670.00 MiB memory in use. Process 16924 has 690.00 MiB memory in use. Process 16928 has 694.00 MiB memory in use. Process 16932 has 678.00 MiB memory in use. Process 16933 has 306.00 MiB memory in use. Process 16949 has 692.00 MiB memory in use. Process 17008 has 530.00 MiB memory in use. Process 17019 has 656.00 MiB memory in use. Process 17020 has 656.00 MiB memory in use. Process 17056 has 282.00 MiB memory in use. Process 17055 has 454.00 MiB memory in use. Process 17145 has 222.00 MiB memory in use. Process 17143 has 224.00 MiB memory in use. Process 17159 has 222.00 MiB memory in use. Process 17170 has 184.00 MiB memory in use. Of the allocated memory 223.90 MiB is allocated by PyTorch, and 6.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_steps = 20\n",
    "    safe_gpu_memory_quotas = [memory_quota - 6 * 1024**3 for memory_quota in gpu_memory_quotas]\n",
    "    _, _, time_taken = parallelize_runs(safe_gpu_memory_quotas, task_memory_usages, test_steps, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408f2a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Computing the solution for every task, while saturating memory and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3788f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T04:10:47.619864Z",
     "iopub.status.busy": "2025-03-30T04:10:47.619663Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    time_per_step = time_taken / test_steps\n",
    "    time_left = end_time - time.time()\n",
    "    n_steps = int(time_left // time_per_step)\n",
    "    _, solutions_dict, time_taken = parallelize_runs(safe_gpu_memory_quotas, task_memory_usages, n_steps, verbose=True)\n",
    "    \n",
    "    # Format the solutions and put into submission file\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump(solutions_dict, f, indent=4)\n",
    "        \n",
    "    print(n_tasks, 'tasks solved.')\n",
    "    print(n_steps, 'steps taken.')\n",
    "    print(time_taken, 'seconds taken.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaL4",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 7001095,
     "sourceId": 11212096,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 424.761511,
   "end_time": "2025-04-24T19:25:48.664496",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-24T19:18:43.902985",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
